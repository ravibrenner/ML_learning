---
title: "tidymodels"
author: "Ravi Brenner"
date: "2025-06-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE)
```

Following along with the tidymodels tutorial found here: https://www.tidymodels.org/start/models/

I have a lot of R experience, and some experience with caret and tidymodels too, so hopefully this will be easy for me.

# Build a model
```{r}
library(tidymodels)
library(readr)       # for importing data
library(broom.mixed) # for converting bayesian models to tidy tibbles
library(dotwhisker)  # for visualizing regression results

theme_set(theme_bw())
```

Read in sea urchins data
```{r}
urchins <- read_csv("https://tidymodels.org/start/models/urchins.csv") |>
  setNames(c("food_regime","initial_volume","width")) |>
  mutate(food_regime = factor(food_regime, levels = c("Initial", "Low", "High")))

head(urchins)
str(urchins)
```

We can quickly plot this data, since it isn't very large

```{r}
ggplot(urchins,
       aes(x = initial_volume, y = width , color = food_regime)) +
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  scale_color_viridis_d(option = "plasma", end = 0.7) 
```

So there's a generally positive relationship, and it appears to be impacted by food_regime

## fitting a simple model

Creating the model in tidymodels means creating a pipeline of components

```{r}
lm_mod <- linear_reg() 
```

```{r}
lm_fit <- lm_mod |>
  fit(width ~ initial_volume * food_regime, data = urchins)

tidy(lm_fit)
```

```{r}
tidy(lm_fit) |>
  dotwhisker::dwplot(dot_args = list(size = 2,color = "black"),
                     whisker_args = list(color = "black"),
                     vline = geom_vline(xintercept = 0, color = "gray",linetype = 2))
```

So we very easily fit a model. `fit` from parsnip is clearly very similar to `train` from caret

## Predicting with the model

```{r}
new_points <- expand_grid(initial_volume = 20, 
                          food_regime = c("Initial", "Low", "High"))

mean_pred <- predict(lm_fit, new_data = new_points)
mean_pred

conf_int_pred <- predict(lm_fit, new_data = new_points,
                         type = "conf_int")
conf_int_pred

plot_data <- new_points |>
  bind_cols(mean_pred) |>
  bind_cols(conf_int_pred)
```

```{r}
ggplot(plot_data, aes(x = food_regime)) + 
  geom_point(aes(y = .pred)) + 
  geom_errorbar(aes(ymin = .pred_lower, 
                    ymax = .pred_upper),
                width = .2) + 
  labs(y = "urchin size")
```

Very simple, and familiar from working with caret.

## use a different engine

We can train more complicated models using other engines. here is a stan_glm model

```{r}
prior_dist <- rstanarm::student_t(df = 1)

set.seed(123)

# creating the model itself
bayes_mod <- linear_reg() |>
  set_engine("stan",
             prior_intercept = prior_dist,
             prior = prior_dist)

bayes_fit <- bayes_mod |>
  fit(width ~ initial_volume * food_regime, data = urchins)
```

```{r}
tidy(bayes_fit, conf.int = T)
```

We can now recycle our code from earlier

```{r}
bayes_plot_data <- new_points |>
  bind_cols(predict(bayes_fit, new_data = new_points)) |>
  bind_cols(predict(bayes_fit, new_data = new_points, type = "conf_int"))
```

```{r}
ggplot(bayes_plot_data, aes(x = food_regime)) + 
  geom_point(aes(y = .pred)) + 
  geom_errorbar(aes(ymin = .pred_lower, 
                    ymax = .pred_upper),
                width = .2) + 
  labs(y = "urchin size") + 
  ggtitle("Bayesian model with t(1) prior dist")
```

# Preprocess data with recipes
```{r}
library(nycflights13)
library(skimr)
```

Import the data
```{r}
set.seed(123)

flights_data <- flights |>
  mutate(arr_delay = if_else(arr_delay >= 30, "late","on_time"),
         arr_delay = factor(arr_delay),
         date = lubridate::as_date(time_hour)) |>
  inner_join(weather, by = join_by("origin","time_hour")) |>
  select(dep_time, flight, origin, dest, air_time,
         distance, carrier, date, arr_delay, time_hour) |>
  na.omit() |>
  mutate(across(where(is.character), as.factor))
```

check how many flights arrived late
```{r}
flights_data |>
  count(arr_delay) |>
  mutate(pct = n / sum(n))
```

check out the data using glimpse (like `str()`)
```{r}
glimpse(flights_data)
```

note that arr_delay is a binary outcome variable, and that flight and time_hour are unique to each row.

```{r}
flights_data |>
  skim(dest,carrier)
```
104 destinations and 16 carriers, which are large numbers for categorical variables. may need to deal with that later.

data splitting
```{r}
set.seed(222)

data_split <- initial_split(flights_data, prop = 0.75)

train_data <- training(data_split)
test_data <- testing(data_split)
```

## creating the recipe

For a simple glm model. The recipe function takes a formula and the data. then, you add roles to the recipe, specifying what each column should do in the model. in this case we specify the IDs, since they shouldn't really be included in the model
```{r}
flights_rec <- recipe(arr_delay ~ ., data = train_data) |>
  update_role(flight, time_hour, new_role = "ID")
```

Now we want to create some features ("feature engineering"). We could just create new columns, and then select the ones we want in the model (e.g. using dplyr). however we can make it part of the recipe workflow to maintain the full data structure

Here we are doing some modifications to the date column. keep_original_cols = FALSE drops the old in favor of the new. we can also create dummy variables
```{r}
flights_rec <- recipe(arr_delay ~ ., data = train_data) |>
  update_role(flight, time_hour, new_role = "ID") |>
  step_date(date, features = c("dow","month")) |>            
  step_holiday(date, 
               holidays = timeDate::listHolidays("US"), 
               keep_original_cols = FALSE) |>
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors()) # removes factor levels with a single value (zero variance = zv)
```

All that work has just written the recipe of what should occur, nothing has actually happened.

Now we define the model as before
```{r}
glm_mod <- logistic_reg() |>
  set_engine("glm")
```

Now create the workflow
```{r}
flights_wflow <- workflow() |>
  add_model(glm_mod) |>
  add_recipe(flights_rec)
```

Now fit the actual model
```{r}
flights_fit <- flights_wflow |>
  fit(data = train_data)
```

```{r}
flights_fit |>
  extract_fit_parsnip() |>
  tidy()
```

Now we can do predictions. As a reminder, the steps so far were
1. build model
2. create recipe
3. bundle in workflow
4. train workflow using fit

now we have 5. predict
```{r}
predict(flights_fit, test_data)
```

To get probabilities we could set type = "prob" or we could use augment like this:
```{r}
flights_pred <- flights_fit |>
  broom::augment(test_data) 

flights_pred |>
  select(arr_delay,time_hour, flight, .pred_class, .pred_on_time)
```

Finally, to assess performance we can look at the ROC curve
```{r}
flights_pred |>
  roc_curve(truth = arr_delay, .pred_late) |>
  autoplot()

flights_pred |>
  roc_auc(truth = arr_delay, .pred_late)
```

In principle, the recipe/workflow combination earlier should make it easier to try out different models or features. for example we could fit the unmodified data like this:

```{r}
flights_wflow2 <- workflow() |>
  add_model(glm_mod) |>
  add_formula(arr_delay ~ .)

flights_fit2 <- flights_wflow2 |>
  fit(data = train_data |>
        select(-time_hour, -flight))

flights_fit2 |>
  extract_fit_parsnip() |>
  tidy()

flights_pred2 <- flights_fit2 |>
  broom::augment(test_data) 

flights_pred2 |>
  roc_auc(truth = arr_delay, .pred_late)
```


# Evaluate model with resamples
```{r}
library(modeldata)

data(cells, package = "modeldata")
cells
```

There are two values of class, PS for poorly segmented, and WS for well segmented

```{r}
cells |>
  count(class) |>
  mutate(pct = n / sum(n))
```

For data splitting, in this case it has been done for us, so that the proportions in each are consistent
```{r}
set.seed(123)
cell_split <- initial_split(cells |> select(-case),
                            strata = class)

cell_train <- training(cell_split)
cell_test <- testing(cell_split)

cell_train |> count(class) |> mutate(pct = n/sum(n))
cell_test |> count(class) |> mutate(pct = n/sum(n))
```

Here we'll use a random forest modeling approach using ranger. this is a somewhat more opaque modeling procedure than glms

```{r}
rf_mod <- rand_forest(trees = 1000) |>
  set_engine("ranger") |>
  set_mode("classification")
```

Now we can fit the model
```{r}
set.seed(234)
rf_fit <- rf_mod |>
  fit(class ~ ., data = cell_train)

rf_fit
```

we previously saw how to use roc_auc() to check model fit. We could also use accuracy() in theory.

Here it is on the training set
```{r}
rf_training_pred <- predict(rf_fit, cell_train) |>
  bind_cols(predict(rf_fit, cell_train, type = "prob")) |>
  bind_cols(cell_train |> select(class))

rf_training_pred |>
  roc_auc(truth = class, .pred_PS)

rf_training_pred |>
  accuracy(truth = class, .pred_class)
```

Those values are too good to be true. Our model is probably overfit, and there is a performance drop off with the testing data
```{r}
rf_testing_pred <- predict(rf_fit, cell_test) |>
  bind_cols(predict(rf_fit, cell_test, type = "prob")) |>
  bind_cols(cell_test |> select(class))

rf_testing_pred |>
  roc_auc(truth = class, .pred_PS)

rf_testing_pred |>
  accuracy(truth = class, .pred_class)
```

We skipped an important step here, which is resampling! Most commonly we use K fold cross validation.

```{r}
set.seed(345)
folds <- vfold_cv(cell_train, v = 10)
```

```{r}
rf_wf <- 
  workflow() |>
  add_model(rf_mod) |>
  add_formula(class ~ .)

set.seed(456)
rf_fit_rs <- 
  rf_wf |>
  fit_resamples(folds)
```

```{r}
collect_metrics(rf_fit_rs)
```


# Tune model parameters

# Case study

# My personal case study